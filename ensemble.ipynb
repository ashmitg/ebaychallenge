{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6432176,"sourceType":"datasetVersion","datasetId":3704776}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nimport csv\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = '/kaggle/input/challenge/Train_Tagged_Titles.tsv'\n\n# Read the data from the TSV file\ntrained_data = pd.read_csv(file_path, sep=\"\\t\", dtype=str, keep_default_na=False, na_values=[\"\"], quoting=csv.QUOTE_NONE)\ntrained_data = trained_data.replace('No Tag', '0')\n\ntrained_data = trained_data.fillna(method='ffill')\ntrained_data['word_labels'] = trained_data[['Record Number','Tag']].groupby(['Record Number'])['Tag'].transform(lambda x: ','.join(x))\ndata = trained_data[[\"Title\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\ndata.rename(columns={'Title': 'sentence'}, inplace=True)\ndata['sentence'] = data['sentence'].apply(remove_special_characters_from_sentence)\n\nlabel2id = {k: v + 1 for v, k in enumerate(trained_data.Tag.unique())}\n\nid2label = {v + 1: k for v, k in enumerate(trained_data.Tag.unique())}\n\nlabel2id['0']=0\nid2label[0]='0'\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T18:20:10.467396Z","iopub.execute_input":"2023-09-12T18:20:10.467780Z","iopub.status.idle":"2023-09-12T18:20:11.675009Z","shell.execute_reply.started":"2023-09-12T18:20:10.467750Z","shell.execute_reply":"2023-09-12T18:20:11.673574Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertForTokenClassification\n\n\n#models now deleted to comply with E-Bay rules \ntokenizer_gelectra = BertTokenizer.from_pretrained('codern/downstream-gelectra-large')\nmodel_gelectra = BertForTokenClassification.from_pretrained('codern/downstream-gelectra-large')\n\ntokenizer_gbert = BertTokenizer.from_pretrained('codern/downstream-gbert-large')\nmodel_gbert = BertForTokenClassification.from_pretrained('codern/downstream-gbert-large')\n\ntokenizer_guncased = BertTokenizer.from_pretrained('codern/bert-regular-base-uncased')\nmodel_guncased = BertForTokenClassification.from_pretrained('codern/bert-regular-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T18:23:51.948217Z","iopub.execute_input":"2023-09-12T18:23:51.948634Z","iopub.status.idle":"2023-09-12T18:24:39.973569Z","shell.execute_reply.started":"2023-09-12T18:23:51.948602Z","shell.execute_reply":"2023-09-12T18:24:39.971284Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/2.50k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38a56c3b8bad43a6a611212d0cb52136"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f8c024e494c4164afe1b43f395ff2e0"}},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T18:24:42.333970Z","iopub.execute_input":"2023-09-12T18:24:42.334373Z","iopub.status.idle":"2023-09-12T18:24:42.339987Z","shell.execute_reply.started":"2023-09-12T18:24:42.334343Z","shell.execute_reply":"2023-09-12T18:24:42.338811Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def extractor(sentence,tokenizer,model):\n    sentence = remove_special_characters_from_sentence(sentence)\n    inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n\n    # move to gpu\n    ids = inputs[\"input_ids\"].to(device)\n    mask = inputs[\"attention_mask\"].to(device)\n    # forward pass\n    outputs = model(ids, mask)\n    logits = outputs[0]\n\n    active_logits = logits.view(-1, model.num_labels) # shape\n    flattened_predictions = torch.argmax(active_logits, axis=1) # tokenize\n\n    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n    token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n    wp_preds = list(zip(tokens, token_predictions)) # prediction per word\n\n    word_level_predictions = []\n    for pair in wp_preds:\n\n      if (pair[0].startswith(\"##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n\n        continue\n      else:\n        word_level_predictions.append(pair[1])\n\n    str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n    return word_level_predictions\n\nsentence = 'New Balance Sneakers Damen Freizeitschuhe Turnschuhe Gr . DE 42.5 Kun ... # 19f7d45'\nprint(extractor(sentence,tokenizer_gbert,model_gbert)==extractor(sentence,tokenizer_guncased,model_guncased))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T19:13:24.025534Z","iopub.execute_input":"2023-09-12T19:13:24.025946Z","iopub.status.idle":"2023-09-12T19:13:25.245284Z","shell.execute_reply.started":"2023-09-12T19:13:24.025915Z","shell.execute_reply":"2023-09-12T19:13:25.244097Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"file_path = '/kaggle/input/challenge/Listing_Titles.tsv'\n\n# Read the data from the TSV file\nlisting_data = pd.read_csv(file_path, sep=\"\\t\", dtype=str, keep_default_na=False, na_values=[\"\"], quoting=csv.QUOTE_NONE)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T19:26:44.376594Z","iopub.execute_input":"2023-09-12T19:26:44.377076Z","iopub.status.idle":"2023-09-12T19:27:07.940352Z","shell.execute_reply.started":"2023-09-12T19:26:44.377045Z","shell.execute_reply":"2023-09-12T19:27:07.939223Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"listing_data = listing_data[5000:30000]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T19:27:10.948868Z","iopub.execute_input":"2023-09-12T19:27:10.949313Z","iopub.status.idle":"2023-09-12T19:27:10.955592Z","shell.execute_reply.started":"2023-09-12T19:27:10.949279Z","shell.execute_reply":"2023-09-12T19:27:10.954325Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"listing_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T19:27:15.624093Z","iopub.execute_input":"2023-09-12T19:27:15.624503Z","iopub.status.idle":"2023-09-12T19:27:15.634547Z","shell.execute_reply.started":"2023-09-12T19:27:15.624457Z","shell.execute_reply":"2023-09-12T19:27:15.633655Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"     Record Number                                              Title\n5000          5001  NIKE FREE RUN 3 SHIELD 5.0 SNEAKERS LAUFSCHUHE...\n5001          5002           DAMEN SCHUHE 153351 SNEAKER WEISS 38 NEU\n5002          5003  Converse Sneakers Damen Gr . DE 36 Leder grau ...\n5003          5004                       Adidas Freizeitschuh Gr UK 9\n5004          5005  K Swiss Schuhe schwarz Leder größe 41 low snea...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Record Number</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5000</th>\n      <td>5001</td>\n      <td>NIKE FREE RUN 3 SHIELD 5.0 SNEAKERS LAUFSCHUHE...</td>\n    </tr>\n    <tr>\n      <th>5001</th>\n      <td>5002</td>\n      <td>DAMEN SCHUHE 153351 SNEAKER WEISS 38 NEU</td>\n    </tr>\n    <tr>\n      <th>5002</th>\n      <td>5003</td>\n      <td>Converse Sneakers Damen Gr . DE 36 Leder grau ...</td>\n    </tr>\n    <tr>\n      <th>5003</th>\n      <td>5004</td>\n      <td>Adidas Freizeitschuh Gr UK 9</td>\n    </tr>\n    <tr>\n      <th>5004</th>\n      <td>5005</td>\n      <td>K Swiss Schuhe schwarz Leder größe 41 low snea...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-12T19:57:08.501244Z","iopub.execute_input":"2023-09-12T19:57:08.502315Z","iopub.status.idle":"2023-09-12T19:57:25.382837Z","shell.execute_reply.started":"2023-09-12T19:57:08.502254Z","shell.execute_reply":"2023-09-12T19:57:25.381084Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\nfrom collections import Counter\n\n\nresult_rows = []\n\n# Assuming you already have 'listing_data' and 'label2id' defined\n\nfor i, row in tqdm(listing_data.iterrows(), total=len(listing_data), desc=\"Processing\"):\n    record_number = row['Record Number']\n    title = row['Title']\n    characteristics_guncased = extractor(title, tokenizer_guncased, model_guncased) \n    characteristics_gelectra = extractor(title, tokenizer_gelectra, model_gelectra)\n    characteristics_gbert = extractor(title, tokenizer_gbert, model_gbert)\n    \n    characteristics = [max(Counter(x), key=Counter(x).get) for x in zip(characteristics_guncased, characteristics_gelectra, characteristics_gbert)]\n\n    title = title.split()\n    \n    for index, value in enumerate(title):\n        aspect_name = characteristics[index]\n        \n        if aspect_name == '0' or aspect_name == 0 or aspect_name == 'No Tag':\n            continue\n        \n        if len(characteristics) != len(title):\n            print(record_number, title)\n        \n        # Check if the current row matches the previous row's Record Number and Aspect Name\n        if i > 0 and len(result_rows)>0 and record_number == result_rows[-1]['Record Number'] and aspect_name == result_rows[-1]['Aspect Name']:\n            # Combine the Aspect Value with the previous row\n            result_rows[-1]['Aspect Value'] += ' ' + value\n        else:\n            # Add a new row to the list\n            result_rows.append({'Record Number': record_number, 'Aspect Name': aspect_name, 'Aspect Value': value})\n\n# Create the DataFrame from the accumulated rows\nresult_df = pd.DataFrame(result_rows)\n\nresult_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T19:57:52.610830Z","iopub.execute_input":"2023-09-12T19:57:52.611242Z","iopub.status.idle":"2023-09-12T21:51:15.216402Z","shell.execute_reply.started":"2023-09-12T19:57:52.611211Z","shell.execute_reply":"2023-09-12T21:51:15.212879Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"Processing: 100%|██████████| 25000/25000 [1:53:22<00:00,  3.68it/s]  \n","output_type":"stream"},{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"  Record Number   Aspect Name      Aspect Value\n0          5001         Marke              NIKE\n1          5001  Produktlinie              FREE\n2          5001        Modell  RUN 3 SHIELD 5.0\n3          5001          Stil          SNEAKERS\n4          5001    Produktart        LAUFSCHUHE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Record Number</th>\n      <th>Aspect Name</th>\n      <th>Aspect Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5001</td>\n      <td>Marke</td>\n      <td>NIKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5001</td>\n      <td>Produktlinie</td>\n      <td>FREE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5001</td>\n      <td>Modell</td>\n      <td>RUN 3 SHIELD 5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5001</td>\n      <td>Stil</td>\n      <td>SNEAKERS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5001</td>\n      <td>Produktart</td>\n      <td>LAUFSCHUHE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output_file_path = '/kaggle/working/evalensemble.tsv'\n\n# Save the DataFrame to a CSV file with tab-separated values (TSV)\nresult_df.to_csv(output_file_path, sep='\\t', index=False)\n\nprint(\"finish\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T21:52:17.800230Z","iopub.execute_input":"2023-09-12T21:52:17.801397Z","iopub.status.idle":"2023-09-12T21:52:18.340039Z","shell.execute_reply.started":"2023-09-12T21:52:17.801313Z","shell.execute_reply":"2023-09-12T21:52:18.338350Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"finish\n","output_type":"stream"}]}]}